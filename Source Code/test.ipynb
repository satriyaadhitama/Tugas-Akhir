{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from IPython import display\n",
    "import pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportModel(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "    # Accept either a string-filename or a batch of waveforms.\n",
    "    # YOu could add additional signatures for a single wave, or a ragged-batch. \n",
    "    self.__call__.get_concrete_function(\n",
    "        x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "    self.__call__.get_concrete_function(\n",
    "       x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    # If they pass a string, load the file and decode it. \n",
    "    if x.dtype == tf.string:\n",
    "      x = tf.io.read_file(x)\n",
    "      x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "      x = tf.squeeze(x, axis=-1)\n",
    "      x = x[tf.newaxis, :]\n",
    "\n",
    "    x = get_spectrogram(x)  \n",
    "    result = self.model(x, training=False)\n",
    "\n",
    "    class_ids = tf.argmax(result, axis=-1)\n",
    "    class_names = tf.gather(label_names, class_ids)\n",
    "    return {'predictions':result,\n",
    "            'class_ids': class_ids,\n",
    "            'class_names': class_names}\n",
    "    \n",
    "export = ExportModel(model)\n",
    "tf.saved_model.save(export, \"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram\n",
    "\n",
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "  \n",
    "train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "test_spectrogram_ds = make_spec_ds(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84c8bcfd3ece7b8d2e9484bf4ce8517a5a4dbcc142a29f247d8a18b531027092"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
